**Программирование для видеокарт: Общие принципы**

Кратко рассмотрим, как работает программирование для GPU:

*   **Хост (CPU) и Устройство (GPU):** Программа обычно состоит из двух частей:
    *   **Хост-код:** Выполняется на CPU, управляет общей логикой, подготавливает данные, запускает вычисления на GPU и обрабатывает результаты.
    *   **Код устройства (ядра):** Выполняется на GPU. Это специальные функции, написанные для параллельной обработки данных.
*   **Массовый параллелизм (SIMT/SIMD):**
    *   **SIMD (Single Instruction, Multiple Data):** Одна инструкция применяется одновременно к множеству элементов данных. Это фундаментальный принцип работы GPU.
    *   **SIMT (Single Instruction, Multiple Threads):** Современные GPU используют эту модель. Множество легковесных потоков (называемых *work-items* в OpenCL или *threads* в CUDA) выполняют одну и ту же программу (ядро), но каждый со своими данными и своим уникальным идентификатором. GPU аппаратно управляет этими потоками.
*   **Память:**
    *   **Глобальная память устройства (Global Memory):** Большая, но относительно медленная память на видеокарте. Доступна всем потокам GPU. Именно сюда хост копирует исходные данные и отсюда забирает результаты.
    *   **Локальная память (Local Memory / Shared Memory):** Меньшая по объему, но значительно более быстрая память, разделяемая между группой потоков (*work-group* в OpenCL). Используется для оптимизации доступа к данным.
    *   **Приватная память (Private Memory):** Регистры и кэш, доступные только одному потоку GPU. Самая быстрая.
*   **Ядра (Kernels):** Функции, написанные на специальном языке (OpenCL C, CUDA C++), которые запускаются на GPU. Одно ядро выполняется одновременно тысячами потоков.
*   **Рабочие элементы (Work-items) и Рабочие группы (Work-groups):**
    *   `work-item`: Один "поток" на GPU, выполняющий экземпляр ядра. У каждого есть уникальный глобальный (`get_global_id()`) и локальный (`get_local_id()`) идентификатор.
    *   `work-group`: Группа work-items, которые могут взаимодействовать через локальную память и барьеры синхронизации.
*   **Запуск ядер:** Хост указывает, сколько work-items нужно запустить и как их сгруппировать в work-groups.

**Архитектура видеокарт, с которой работает код:**

Код использует OpenCL, который является открытым стандартом и может работать на GPU разных производителей (NVIDIA, AMD, Intel) и даже на CPU и других ускорителях. Архитектура GPU, на которой это будет эффективно работать, характеризуется:

1.  **Множеством вычислительных блоков (Compute Units / Streaming Multiprocessors):** Каждый такой блок содержит множество более простых ядер (ALU), способных выполнять арифметические и логические операции.
2.  **Иерархической памятью:** Как описано выше (глобальная, локальная/разделяемая, приватная).
3.  **Планировщиком потоков:** Аппаратно управляет выполнением тысяч work-items на вычислительных блоках.

Когда ядро OpenCL запускается, его работа распределяется по этим вычислительным блокам. Work-items внутри work-group обычно выполняются на одном вычислительном блоке, что позволяет им эффективно использовать локальную память.
